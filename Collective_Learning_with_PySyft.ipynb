{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates collective learning with PySyft.\n",
    "\n",
    "First step is to import some modules and hook PySyft onto torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as nn_func\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import syft as sy\n",
    "\n",
    "\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define some arguments for the model and training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 64\n",
    "        self.n_batches_for_vote = 5\n",
    "        self.test_batch_size = 1000\n",
    "        self.epochs = 5\n",
    "        self.lr = 0.01\n",
    "        self.no_cuda = False\n",
    "        self.seed = 1\n",
    "        self.log_interval = 30\n",
    "        self.n_hospitals = 5\n",
    "        self.vote_threshold = (self.n_hospitals - 1) // 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4 * 4 * 50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn_func.relu(self.conv1(x))\n",
    "        x = nn_func.max_pool2d(x, 2, 2)\n",
    "        x = nn_func.relu(self.conv2(x))\n",
    "        x = nn_func.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4 * 4 * 50)\n",
    "        x = nn_func.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn_func.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the interesting bit: collective learning in PySyft. The function below performs one round of collective learning. First the original weights of the model are saved. Then a random worker is selected to perform training. After the training the model is sent to the other workers. Each worker evaluates the loss on a set number of batches of the training set. If the loss is lower for the new weights then that worker has a positive vote, otherwise it's a negative vote. The votes are summed up and if they are over the voting threshold then the new weights are accepted. If the positive votes do not pass the threshold then the weights are replaced by the saved weights from the beginning of the round."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSSES = {}  # dictionary of loss for each worker\n",
    "\n",
    "def colearn_train(args, model: Net, device,\n",
    "                  federated_train_loader: sy.FederatedDataLoader,\n",
    "                  optimizer, epoch, workers):\n",
    "    global LOSSES\n",
    "    model.train()  # sets model to \"training\" mode. Does not perform training.\n",
    "    # need to save the state dict of the old model\n",
    "    state_dict = model.state_dict()\n",
    "    # pick a random hospital\n",
    "    proposer_index = randint(0, len(workers) - 1)\n",
    "    proposer = workers[proposer_index]\n",
    "    print(\"Proposer\", proposer_index, proposer)\n",
    "    model.send(proposer)\n",
    "\n",
    "    # go through all the batches for hosp_n, perform training, get model back\n",
    "    for batch_idx, data_dict in enumerate(federated_train_loader):  # a distributed dataset\n",
    "        data, target = data_dict[proposer]\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = nn_func.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss = loss.get()  # get the loss back\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * args.batch_size,\n",
    "                len(federated_train_loader) * args.batch_size,\n",
    "                100. * batch_idx * len(workers) / len(federated_train_loader), loss.item()))\n",
    "\n",
    "    # send to others and vote\n",
    "    model.get()\n",
    "    losses = test_on_training_set(args, model, device, federated_train_loader, workers)\n",
    "    vote = False\n",
    "    print(\"Doing voting\")\n",
    "    if not LOSSES:\n",
    "        vote = True\n",
    "        print(\"First round, no voting\")\n",
    "        LOSSES = losses\n",
    "    else:\n",
    "        votes = 0\n",
    "        for worker, old_loss in LOSSES.items():\n",
    "            if worker != proposer:\n",
    "                if old_loss > losses[worker]:\n",
    "                    votes += 1\n",
    "                    print(worker, \"votes yes\")\n",
    "                else:\n",
    "                    print(worker, \"votes no\")\n",
    "        if votes >= args.vote_threshold:\n",
    "            print(\"Vote succeeded\")\n",
    "            vote = True\n",
    "            LOSSES = losses\n",
    "    if not vote:\n",
    "        print(\"Vote failed\")\n",
    "        # then load the old weights into the model\n",
    "        model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function evaluates the loss for each worker on n random batches from the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_training_set(args: Arguments, model, device, train_loader, workers):\n",
    "    model.eval()  # sets model to \"eval\" mode.\n",
    "    losses = {w: 0 for w in workers}\n",
    "    batch_count = 0\n",
    "    with torch.no_grad():\n",
    "        for data_dict in train_loader:\n",
    "            for worker, (data, target) in data_dict.items():\n",
    "                model.send(data.location)\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                losses[worker] += nn_func.nll_loss(output, target, reduction='sum').get()  # sum up batch loss\n",
    "                model.get()\n",
    "            batch_count += 1\n",
    "            if batch_count == args.n_batches_for_vote:\n",
    "                break\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to evaluate the model performance on an independent test set to get the proper accuracy and loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, device, test_loader):\n",
    "    model.eval()  # sets model to \"eval\" mode.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += nn_func.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the functions for training and testing, the learning can begin. The code below creates the virtual workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "\n",
    "hospitals = []\n",
    "for i in range(args.n_hospitals):\n",
    "    hospitals.append(sy.VirtualWorker(hook, id=\"hospital \" + str(i)))\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(args.seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a federated dataset for training and a non-federated dataset for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_train_loader = sy.FederatedDataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])).federate(hospitals),\n",
    "    batch_size=args.batch_size, shuffle=True, iter_per_worker=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=args.test_batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we create the optimizer and perform training for several epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposer 0 <VirtualWorker id:hospital 0 #objects:2>\n",
      "Train Epoch: 1 [0/60032 (0%)]\tLoss: 2.309244\n",
      "Train Epoch: 1 [1920/60032 (16%)]\tLoss: 2.162263\n",
      "Train Epoch: 1 [3840/60032 (32%)]\tLoss: 1.917882\n",
      "Train Epoch: 1 [5760/60032 (48%)]\tLoss: 1.441066\n",
      "Train Epoch: 1 [7680/60032 (64%)]\tLoss: 0.859634\n",
      "Train Epoch: 1 [9600/60032 (80%)]\tLoss: 0.529702\n",
      "Train Epoch: 1 [11520/60032 (96%)]\tLoss: 0.630420\n",
      "Doing voting\n",
      "First round, no voting\n",
      "\n",
      "Test set: Average loss: 0.5020, Accuracy: 8663/10000 (87%)\n",
      "\n",
      "Proposer 3 <VirtualWorker id:hospital 3 #objects:2>\n",
      "Train Epoch: 2 [0/60032 (0%)]\tLoss: 0.500130\n",
      "Train Epoch: 2 [1920/60032 (16%)]\tLoss: 0.406979\n",
      "Train Epoch: 2 [3840/60032 (32%)]\tLoss: 0.460780\n",
      "Train Epoch: 2 [5760/60032 (48%)]\tLoss: 0.621519\n",
      "Train Epoch: 2 [7680/60032 (64%)]\tLoss: 0.491008\n",
      "Train Epoch: 2 [9600/60032 (80%)]\tLoss: 0.552320\n",
      "Train Epoch: 2 [11520/60032 (96%)]\tLoss: 0.441276\n",
      "Doing voting\n",
      "<VirtualWorker id:hospital 0 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 1 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 2 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 4 #objects:4> votes yes\n",
      "Vote succeeded\n",
      "\n",
      "Test set: Average loss: 0.3350, Accuracy: 9009/10000 (90%)\n",
      "\n",
      "Proposer 0 <VirtualWorker id:hospital 0 #objects:2>\n",
      "Train Epoch: 3 [0/60032 (0%)]\tLoss: 0.315413\n",
      "Train Epoch: 3 [1920/60032 (16%)]\tLoss: 0.334564\n",
      "Train Epoch: 3 [3840/60032 (32%)]\tLoss: 0.381194\n",
      "Train Epoch: 3 [5760/60032 (48%)]\tLoss: 0.210902\n",
      "Train Epoch: 3 [7680/60032 (64%)]\tLoss: 0.272020\n",
      "Train Epoch: 3 [9600/60032 (80%)]\tLoss: 0.443072\n",
      "Train Epoch: 3 [11520/60032 (96%)]\tLoss: 0.233219\n",
      "Doing voting\n",
      "<VirtualWorker id:hospital 1 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 2 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 3 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 4 #objects:4> votes yes\n",
      "Vote succeeded\n",
      "\n",
      "Test set: Average loss: 0.2279, Accuracy: 9336/10000 (93%)\n",
      "\n",
      "Proposer 2 <VirtualWorker id:hospital 2 #objects:2>\n",
      "Train Epoch: 4 [0/60032 (0%)]\tLoss: 0.258996\n",
      "Train Epoch: 4 [1920/60032 (16%)]\tLoss: 0.406119\n",
      "Train Epoch: 4 [3840/60032 (32%)]\tLoss: 0.197182\n",
      "Train Epoch: 4 [5760/60032 (48%)]\tLoss: 0.418370\n",
      "Train Epoch: 4 [7680/60032 (64%)]\tLoss: 0.547244\n",
      "Train Epoch: 4 [9600/60032 (80%)]\tLoss: 0.164592\n",
      "Train Epoch: 4 [11520/60032 (96%)]\tLoss: 0.066862\n",
      "Doing voting\n",
      "<VirtualWorker id:hospital 0 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 1 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 3 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 4 #objects:4> votes no\n",
      "Vote succeeded\n",
      "\n",
      "Test set: Average loss: 0.2068, Accuracy: 9378/10000 (94%)\n",
      "\n",
      "Proposer 4 <VirtualWorker id:hospital 4 #objects:2>\n",
      "Train Epoch: 5 [0/60032 (0%)]\tLoss: 0.287869\n",
      "Train Epoch: 5 [1920/60032 (16%)]\tLoss: 0.177022\n",
      "Train Epoch: 5 [3840/60032 (32%)]\tLoss: 0.126695\n",
      "Train Epoch: 5 [5760/60032 (48%)]\tLoss: 0.198957\n",
      "Train Epoch: 5 [7680/60032 (64%)]\tLoss: 0.227562\n",
      "Train Epoch: 5 [9600/60032 (80%)]\tLoss: 0.217691\n",
      "Train Epoch: 5 [11520/60032 (96%)]\tLoss: 0.194701\n",
      "Doing voting\n",
      "<VirtualWorker id:hospital 0 #objects:4> votes no\n",
      "<VirtualWorker id:hospital 1 #objects:4> votes no\n",
      "<VirtualWorker id:hospital 2 #objects:4> votes yes\n",
      "<VirtualWorker id:hospital 3 #objects:4> votes yes\n",
      "Vote succeeded\n",
      "\n",
      "Test set: Average loss: 0.1595, Accuracy: 9509/10000 (95%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    colearn_train(args, model, device, federated_train_loader, optimizer, epoch, hospitals)\n",
    "    test(args, model, device, test_loader)\n",
    "    \n",
    "print(\"Training complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
